{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "import urllib\n",
    "import tempfile\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils import load_config\n",
    "from tad_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm_orig\n",
    "tqdm_orig.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    config['input_files']['raw_disgenet'],\n",
    "    usecols=['snpId','diseaseId','diseaseName','source'])\n",
    "df.rename(columns={'diseaseId': 'UMLS_CUI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide whether to use hg19 or hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel and rerun all cells after changing this cell\n",
    "USE_HG38 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HG38:\n",
    "    genome_version = 'hg38'\n",
    "    tad_data_fname = 'results/tads_hESC_hg38.tsv'\n",
    "    \n",
    "    def snp_position_convert(row):\n",
    "        # don't do anything, as positions are already in hg38\n",
    "        return row.position\n",
    "else:\n",
    "    genome_version = 'hg19'\n",
    "    tad_data_fname = config['input_files']['tad_coordinates_hg19']\n",
    "    \n",
    "    # get hg19 SNP-positions\n",
    "    df_snp_pos_map = pd.read_csv('results/snp_positions_hg19.csv')\n",
    "    df_snp_pos_map['chrom'] = df_snp_pos_map['chrom'].apply(lambda x: x[3:])\n",
    "    df_snp_pos_map['pos'] = list(zip(df_snp_pos_map['chrom'], df_snp_pos_map['end']))\n",
    "\n",
    "    snp_pos_hg19 = df_snp_pos_map.set_index('SNPS').to_dict()['pos']\n",
    "    def snp_position_convert(row):\n",
    "        # convert BP-position from hg38 to hg19\n",
    "        if row.snpId not in snp_pos_hg19:\n",
    "            return np.nan\n",
    "        \n",
    "        chrom, pos_hg19 = snp_pos_hg19[row.snpId]\n",
    "        assert row.chromosome == chrom\n",
    "        return pos_hg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Disease-Ontology OWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/doid.owl') as fd:\n",
    "    soup = BeautifulSoup(fd, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_owl_data = {}\n",
    "\n",
    "for entry in tqdm(soup.find_all('Class')):\n",
    "    doid = entry['rdf:about'].split('/')[-1]\n",
    "    \n",
    "    # get label\n",
    "    lbl = entry.find('rdfs:label').get_text()\n",
    "    \n",
    "    # get UMLS_CUI/EFO terms\n",
    "    efo_terms = []\n",
    "    cui_terms = []\n",
    "    for xref in entry.find_all('oboInOwl:hasDbXref'):\n",
    "        txt = xref.get_text()\n",
    "        if txt.startswith('UMLS_CUI:'):\n",
    "            cui = txt.split(':')[-1]\n",
    "            cui_terms.append(cui)\n",
    "        elif txt.startswith('EFO:'):\n",
    "            efo = txt.split(':')[-1]\n",
    "            efo_terms.append(efo)\n",
    "    \n",
    "    assert doid not in node_owl_data\n",
    "    node_owl_data[doid] = {\n",
    "        'label': lbl,\n",
    "        'UMLS_CUI': cui_terms,\n",
    "        'EFO': efo_terms\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate lates GWAS-catalog version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat = pd.read_table('data/gwas_catalog_v1.0.1-associations_e91_r2018-03-13.tsv', low_memory=False)\n",
    "\n",
    "df_gwascat = df_gwascat[['SNP_ID_CURRENT', 'MAPPED_TRAIT_URI', 'MAPPED_TRAIT']]\n",
    "df_gwascat.dropna(inplace=True)\n",
    "df_gwascat.rename(columns={\n",
    "    'SNP_ID_CURRENT': 'snpId', 'MAPPED_TRAIT_URI': 'EFO', 'MAPPED_TRAIT': 'diseaseName'\n",
    "}, inplace=True)\n",
    "\n",
    "df_gwascat['snpId'] = df_gwascat['snpId'].apply(lambda x: f'rs{x}')\n",
    "df_gwascat['source'] = 'GWASCUSTOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map EFO to UMLS_CUI\n",
    "efo2cui_map = {}\n",
    "for entry in node_owl_data.values():\n",
    "    for efo in entry['EFO']:\n",
    "        assert efo not in efo2cui_map, efo\n",
    "        for cui in entry['UMLS_CUI']:\n",
    "            efo2cui_map[f'EFO_{efo}'] = cui\n",
    "\n",
    "df_gwascat['UMLS_CUI'] = df_gwascat['EFO'].str.split(' *, *').apply(\n",
    "    lambda xs: sorted([efo2cui_map.get(x[25:], str(np.nan)) for x in xs])[0])\n",
    "df_gwascat = df_gwascat[df_gwascat['UMLS_CUI'] != 'nan']\n",
    "df_gwascat.drop('EFO', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_gwascat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'cache/doid_graph.edgelist.gz'\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    import onto2nx\n",
    "    nx.write_edgelist(onto2nx.parse_owl_rdf('data/doid.owl'), fname)\n",
    "else:\n",
    "    print('Cached', fname)\n",
    "    \n",
    "doid_graph = nx.read_edgelist(fname, create_using=nx.DiGraph()).reverse()\n",
    "print(nx.info(doid_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance graph with associations\n",
    "nx.set_node_attributes(doid_graph, node_owl_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out exemplary node (cancer)\n",
    "doid_data = dict(doid_graph.nodes(data=True))\n",
    "\n",
    "doid_data['DOID_162']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cui = []\n",
    "for node, data in tqdm(doid_data.items()):\n",
    "    for term in data['UMLS_CUI']:\n",
    "        data_cui.append((node, data['label'], term))\n",
    "\n",
    "df_cui = pd.DataFrame(data_cui, columns=['DOID','DO_label','UMLS_CUI'])\n",
    "df_cui.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find cancer subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_nodes = nx.descendants(doid_graph, 'DOID_162')\n",
    "\n",
    "data_cancer = [('DOID_162', True)]\n",
    "for n in cancer_nodes:\n",
    "    data_cancer.append((n, True))\n",
    "for n in (doid_graph.nodes() - cancer_nodes):\n",
    "    data_cancer.append((n, False))\n",
    "    \n",
    "df_iscancer = pd.DataFrame(data_cancer, columns=['DOID','is_cancer'])\n",
    "df_iscancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nodes in doid.owl:', len(doid_data))\n",
    "print('Nodes with UMLS_CUI:', df_cui.DOID.unique().size)\n",
    "print('(Non)cancer nodes (should be all):', df_iscancer.DOID.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onto = df_cui.merge(df_iscancer, on='DOID')\n",
    "\n",
    "print(df_onto.shape)\n",
    "df_onto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save disease cancer-classification\n",
    "tmp = df_onto[['UMLS_CUI','is_cancer','DO_label']].copy()\n",
    "tmp.rename(columns={'UMLS_CUI': 'term', 'is_cancer': 'type', 'DO_label': 'label'}, inplace=True)\n",
    "tmp['type'] = tmp['type'].apply(lambda x: 'cancer' if x else 'disease')\n",
    "tmp.to_csv('results/disease_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNP annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve VEP annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_annotations(snps):\n",
    "    _url = 'http://rest.ensembl.org/vep/human/id'\n",
    "    headers = {'Content-Type': 'application/json', 'Accept': 'application/json'}\n",
    "\n",
    "    r = requests.post(_url, headers=headers, data=json.dumps({'ids': snps}))\n",
    "    return r.json() if r.ok else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: in case of update, cache-file must be deleted manually\n",
    "fname = 'cache/snp_annotations.json'\n",
    "\n",
    "if os.path.exists(f'{fname}.gz'):\n",
    "    print('Cached', f'{fname}.gz')\n",
    "    with gzip.open(f'{fname}.gz') as fd:\n",
    "        snp_anno_data = json.load(fd)\n",
    "else:\n",
    "    # setup\n",
    "    snp_anno_data = []\n",
    "\n",
    "    batch_size = 200\n",
    "    snp_list = df['snpId'].unique().tolist()\n",
    "\n",
    "    # request annotations\n",
    "    prev_i = 0\n",
    "    for i in tqdm(range(batch_size, len(snp_list)+batch_size, batch_size)):\n",
    "        i = min(i, len(snp_list))\n",
    "        cur_snps = snp_list[prev_i:i]\n",
    "        assert len(cur_snps) == (i-prev_i), (prev_i, i, len(cur_snps))\n",
    "\n",
    "        res = request_annotations(cur_snps)\n",
    "        assert res is not None\n",
    "        snp_anno_data.extend(res)\n",
    "\n",
    "        prev_i = i\n",
    "        \n",
    "    # cache results\n",
    "    with open(fname, 'w') as fd:\n",
    "        json.dump(snp_anno_data, fd)\n",
    "    !gzip $fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_anno_extract = []\n",
    "for e in snp_anno_data:\n",
    "    snp_anno_extract.append((\n",
    "        e['id'], e['most_severe_consequence'],\n",
    "        e['seq_region_name'], e['start']\n",
    "    ))\n",
    "    \n",
    "df_anno = pd.DataFrame(snp_anno_extract, columns=['snpId', 'variant_type', 'chromosome', 'position'])\n",
    "df_anno.drop_duplicates('snpId', inplace=True)\n",
    "df_anno.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer TAD relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SNP positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snppos = df_anno[['snpId', 'chromosome', 'position']].copy()\n",
    "df_snppos.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TAD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads = pd.read_table(tad_data_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_range_dict(row, dict_):\n",
    "    range_dict_ = dict_.get(row['chromosome'], None)\n",
    "    if range_dict_ is None:\n",
    "        return 'undef'\n",
    "    \n",
    "    return range_dict_[row['position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_anno_20in = parse_tad_annotations('20in', fname=tad_data_fname)\n",
    "df_snppos['TAD_20in'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_20in), axis=1)\n",
    "\n",
    "tad_anno_40in = parse_tad_annotations('40in', fname=tad_data_fname)\n",
    "df_snppos['TAD_40in'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_40in), axis=1)\n",
    "\n",
    "tad_anno_20out = parse_tad_annotations('20out', fname=tad_data_fname)\n",
    "df_snppos['TAD_20out'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_20out), axis=1)\n",
    "\n",
    "tad_anno_40out = parse_tad_annotations('40out', fname=tad_data_fname)\n",
    "df_snppos['TAD_40out'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_40out), axis=1)\n",
    "\n",
    "tad_anno_20inout = parse_tad_annotations('20inout', fname=tad_data_fname)\n",
    "df_snppos['TAD_20inout'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_20inout), axis=1)\n",
    "\n",
    "tad_anno_40inout = parse_tad_annotations('40inout', fname=tad_data_fname)\n",
    "df_snppos['TAD_40inout'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_40inout), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snptads = df_snppos.drop(['chromosome', 'position'], axis=1)\n",
    "df_snptads.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge into DisGeNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy()\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(df_onto, on='UMLS_CUI')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(df_snptads, on='snpId')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(df_anno, how='left')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_sub = df_final.drop(['diseaseName', 'DOID'], axis=1)\n",
    "df_final_sub.rename(columns={'DO_label': 'diseaseName'}, inplace=True)\n",
    "\n",
    "df_final_sub.to_csv(f'results/disgenet_enhanced_{genome_version}.tsv', sep='\\t', index=False)\n",
    "df_final_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
