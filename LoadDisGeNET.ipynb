{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import tempfile\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm_orig\n",
    "tqdm_orig.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    'data/curated_variant_disease_associations.tsv.gz',\n",
    "    usecols=['snpId','diseaseId','diseaseName','source'])\n",
    "df.rename(columns={'diseaseId': 'UMLS_CUI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide whether to use hg19 or hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel and rerun all cells after changing this\n",
    "USE_HG38 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HG38:\n",
    "    genome_version = 'hg38'\n",
    "    tad_data_fname = 'results/tads_hESC_hg38.tsv'\n",
    "    \n",
    "    def snp_position_convert(row):\n",
    "        # don't do anything, as positions are already in hg38\n",
    "        return row.position\n",
    "else:\n",
    "    genome_version = 'hg19'\n",
    "    tad_data_fname = 'data/tads_hESC_hg19_with_ids.txt'\n",
    "    \n",
    "    # get hg19 SNP-positions\n",
    "    df_snp_pos_map = pd.read_csv('results/snp_positions_hg19.csv')\n",
    "    df_snp_pos_map['chrom'] = df_snp_pos_map['chrom'].apply(lambda x: x[3:])\n",
    "    df_snp_pos_map['pos'] = list(zip(df_snp_pos_map['chrom'], df_snp_pos_map['end']))\n",
    "\n",
    "    snp_pos_hg19 = df_snp_pos_map.set_index('SNPS').to_dict()['pos']\n",
    "    def snp_position_convert(row):\n",
    "        # convert BP-position from hg38 to hg19\n",
    "        if row.snpId not in snp_pos_hg19:\n",
    "            return np.nan\n",
    "        \n",
    "        chrom, pos_hg19 = snp_pos_hg19[row.snpId]\n",
    "        assert row.chromosome == chrom\n",
    "        return pos_hg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = onto2nx.parse_owl_rdf('data/doid.owl')\n",
    "#nx.write_edgelist(g, 'results/doid_graph.edgelist.gz')\n",
    "doid_graph = nx.read_edgelist('results/doid_graph.edgelist.gz', create_using=nx.DiGraph()).reverse()\n",
    "print(nx.info(doid_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/doid.owl') as fd:\n",
    "    soup = BeautifulSoup(fd, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_owl_data = {}\n",
    "\n",
    "for entry in tqdm(soup.find_all('Class')):\n",
    "    doid = entry['rdf:about'].split('/')[-1]\n",
    "    \n",
    "    # get label\n",
    "    lbl = entry.find('rdfs:label').get_text()\n",
    "    \n",
    "    # get UMLS_CUI terms\n",
    "    terms = []\n",
    "    for xref in entry.find_all('oboInOwl:hasDbXref'):\n",
    "        txt = xref.get_text()\n",
    "        if txt.startswith('UMLS_CUI:'):\n",
    "            cui = txt.split(':')[-1]\n",
    "            terms.append(cui)\n",
    "    \n",
    "    assert doid not in node_owl_data\n",
    "    node_owl_data[doid] = {\n",
    "        'label': lbl,\n",
    "        'UMLS_CUI': terms\n",
    "    }\n",
    "    \n",
    "nx.set_node_attributes(doid_graph, node_owl_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out exemplary node (cancer)\n",
    "doid_data = dict(doid_graph.nodes(data=True))\n",
    "\n",
    "doid_data['DOID_162']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cui = []\n",
    "for node, data in tqdm(doid_data.items()):\n",
    "    for term in data['UMLS_CUI']:\n",
    "        data_cui.append((node, data['label'], term))\n",
    "\n",
    "df_cui = pd.DataFrame(data_cui, columns=['DOID','DO_label','UMLS_CUI'])\n",
    "df_cui.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find cancer subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_nodes = nx.descendants(doid_graph, 'DOID_162')\n",
    "\n",
    "data_cancer = []\n",
    "for n in cancer_nodes:\n",
    "    data_cancer.append((n, True))\n",
    "for n in (doid_graph.nodes() - cancer_nodes):\n",
    "    data_cancer.append((n, False))\n",
    "    \n",
    "df_iscancer = pd.DataFrame(data_cancer, columns=['DOID','is_cancer'])\n",
    "df_iscancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nodes in doid.owl:', len(doid_data))\n",
    "print('Nodes with UMLS_CUI:', df_cui.DOID.unique().size)\n",
    "print('(Non)cancer nodes (should be all):', df_iscancer.DOID.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onto = df_cui.merge(df_iscancer, on='DOID')\n",
    "\n",
    "print(df_onto.shape)\n",
    "df_onto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save disease cancer-classification\n",
    "tmp = df_onto[['UMLS_CUI','is_cancer','DO_label']].copy()\n",
    "tmp.rename(columns={'UMLS_CUI': 'term', 'is_cancer': 'type', 'DO_label': 'label'}, inplace=True)\n",
    "tmp['type'] = tmp['type'].apply(lambda x: 'cancer' if x else 'disease')\n",
    "tmp.to_csv('results/disease_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer TAD relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SNP positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snppos = pd.read_table(\n",
    "    'data/all_variant_disease_pmid_associations.tsv.gz', usecols=['snpId','chromosome','position'])\n",
    "\n",
    "df_snppos.drop_duplicates(inplace=True)\n",
    "df_snppos.dropna(inplace=True)\n",
    "df_snppos['position'] = df_snppos['position'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_snp_positions = df_snppos.progress_apply(snp_position_convert, axis=1)\n",
    "\n",
    "# save mapping overview\n",
    "if not USE_HG38:\n",
    "    df_tmp = df_snppos.copy()\n",
    "    df_tmp.rename(columns={'position': 'position_hg38'}, inplace=True)\n",
    "    df_tmp['position_hg19'] = new_snp_positions\n",
    "    df_tmp.to_csv('results/snps_hg19_hg38.csv', index=False)\n",
    "\n",
    "df_snppos['position'] = new_snp_positions\n",
    "df_snppos.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snppos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TAD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads = pd.read_table(tad_data_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangeDict(dict):\n",
    "    \"\"\" Optimized for ranges with step==1\n",
    "    \"\"\"\n",
    "    def __getitem__(self, item):\n",
    "        if type(item) != range:\n",
    "            for key in self:\n",
    "                if key.step == 1:\n",
    "                    if key.start <= item < key.stop:\n",
    "                        return self[key]\n",
    "                else:\n",
    "                    if item in key:\n",
    "                        return self[key]\n",
    "        else:\n",
    "            return super().__getitem__(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyTAD(Exception):\n",
    "    pass\n",
    "\n",
    "class OverlappingTADS(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tad_lengths(row, type_):\n",
    "    \"\"\" Get TAD and boundary lengths depending on type\n",
    "    \"\"\"\n",
    "    if type_ not in (\n",
    "        '20in', '40in',\n",
    "        '20out', '40out',\n",
    "        '20inout', '40inout',\n",
    "        '60in', '80in'\n",
    "    ):\n",
    "        raise RuntimeError(f'Invalid type {type_}')\n",
    "\n",
    "    tad_start = row.tad_start\n",
    "    tad_stop = row.tad_stop\n",
    "\n",
    "    # set reach of border\n",
    "    if type_ in ('20in', '20out', '20inout'):\n",
    "        bp_in = bp_out = 20_000\n",
    "    if type_ in ('40in', '40out', '40inout'):\n",
    "        bp_in = bp_out = 40_000\n",
    "    if type_ in ('60in',):\n",
    "        bp_in = bp_out = 60_000\n",
    "    if type_ in ('80in',):\n",
    "        bp_in = bp_out = 80_000\n",
    "\n",
    "    # rescale border length if TAD is too small\n",
    "    tad_len = tad_stop - tad_start\n",
    "    if tad_len <= 0:\n",
    "        raise EmptyTAD(row)\n",
    "    \n",
    "    if tad_len < 2*bp_in:\n",
    "        bp_in = tad_len // 4\n",
    "\n",
    "    # assert that TADs are not overlapping\n",
    "    # rescale borders if they would overlap\n",
    "    dist_prev = (tad_start - row.prev_tad_stop) \\\n",
    "        if (\n",
    "            not np.isnan(row.prev_tad_stop)\n",
    "            and row.chrname == row.prev_tad_chr\n",
    "        ) else float('inf')\n",
    "    dist_next = (row.next_tad_start - tad_stop) \\\n",
    "        if (\n",
    "            not np.isnan(row.next_tad_start)\n",
    "            and row.chrname == row.next_tad_chr\n",
    "        ) else float('inf')\n",
    "    dist_min = min(dist_prev, dist_next)\n",
    "    if dist_min < 0:\n",
    "        raise OverlappingTADS(row)\n",
    "    \n",
    "    if dist_min < 2*bp_out:\n",
    "        bp_out = dist_min // 4\n",
    "\n",
    "    # final sanity checks\n",
    "    bp_in = int(bp_in)\n",
    "    bp_out = int(bp_out)\n",
    "    assert bp_in >= 0 and bp_out >= 0\n",
    "\n",
    "    # return appropriate ranges\n",
    "    if type_ in ('20in', '40in', '60in', '80in'):\n",
    "        return (\n",
    "            range(tad_start, tad_start+bp_in),\n",
    "            range(tad_start+bp_in, tad_stop-bp_in),\n",
    "            range(tad_stop-bp_in, tad_stop)\n",
    "        )\n",
    "    elif type_ in ('20out', '40out'):\n",
    "        return (\n",
    "            range(tad_start-bp_out, tad_start),\n",
    "            range(tad_start, tad_stop),\n",
    "            range(tad_stop, tad_stop+bp_out)\n",
    "        )\n",
    "    elif type_ in ('20inout', '40inout'):\n",
    "        return (\n",
    "            range(tad_start-bp_out, tad_start+bp_in),\n",
    "            range(tad_start+bp_in, tad_stop-bp_in),\n",
    "            range(tad_stop-bp_in, tad_stop+bp_out)\n",
    "        )\n",
    "\n",
    "\n",
    "def parse_tad_annotations(type_, fname=tad_data_fname):\n",
    "        print(f' > Parsing TADs ({type_})', file=sys.stderr)\n",
    "        df_tad = pd.read_table(fname)\n",
    "        df_tad['prev_tad_stop'] = df_tad.tad_stop.shift(1)\n",
    "        df_tad['next_tad_start'] = df_tad.tad_start.shift(-1)\n",
    "        df_tad['prev_tad_chr'] = df_tad.chrname.shift(1)\n",
    "        df_tad['next_tad_chr'] = df_tad.chrname.shift(-1)\n",
    "\n",
    "        error_counter = collections.defaultdict(int)\n",
    "        res = collections.defaultdict(RangeDict)\n",
    "        for row in tqdm(df_tad.itertuples(), total=df_tad.shape[0]):\n",
    "            try:\n",
    "                rb1, rt, rb2 = get_tad_lengths(row, type_)\n",
    "            except EmptyTAD as ex:\n",
    "                error_counter['empty_tad'] += 1\n",
    "            except OverlappingTADS as ex:\n",
    "                error_counter['overlapping_tads'] += 1\n",
    "                \n",
    "            # normalize chromosome name\n",
    "            chrom = row.chrname\n",
    "            if chrom.startswith('chr'):\n",
    "                chrom = chrom[3:]\n",
    "\n",
    "            # store range-associations\n",
    "            res[chrom][rb1] = 'boundary'\n",
    "            res[chrom][rt] = 'tad'\n",
    "            res[chrom][rb2] = 'boundary'\n",
    "            \n",
    "        if error_counter:\n",
    "            print('TAD errors:')\n",
    "            for k,v in sorted(error_counter.items()):\n",
    "                print(f' > {k}: {v}')\n",
    "\n",
    "        return dict(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_range_dict(row, dict_):\n",
    "    range_dict_ = dict_.get(row['chromosome'], None)\n",
    "    if range_dict_ is None:\n",
    "        return 'undef'\n",
    "    \n",
    "    return range_dict_[row['position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_anno_20in = parse_tad_annotations('20in')\n",
    "df_snppos['TAD_20in'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_20in), axis=1)\n",
    "\n",
    "tad_anno_40in = parse_tad_annotations('40in')\n",
    "df_snppos['TAD_40in'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_40in), axis=1)\n",
    "\n",
    "tad_anno_20out = parse_tad_annotations('20out')\n",
    "df_snppos['TAD_20out'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_20out), axis=1)\n",
    "\n",
    "tad_anno_40out = parse_tad_annotations('40out')\n",
    "df_snppos['TAD_40out'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_40out), axis=1)\n",
    "\n",
    "tad_anno_20inout = parse_tad_annotations('20inout')\n",
    "df_snppos['TAD_20inout'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_20inout), axis=1)\n",
    "\n",
    "tad_anno_40inout = parse_tad_annotations('40inout')\n",
    "df_snppos['TAD_40inout'] = df_snppos.progress_apply(lambda x: access_range_dict(x, tad_anno_40inout), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snppos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge into DisGeNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(df_onto, on='UMLS_CUI')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(df_snppos, on='snpId')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_final_sub = df_final.drop(['diseaseName', 'DOID'], axis=1)\n",
    "df_final_sub.rename(columns={'DO_label': 'diseaseName'}, inplace=True)\n",
    "\n",
    "df_final_sub.to_csv(f'results/disgenet_enhanced_{genome_version}.tsv', sep='\\t', index=False)\n",
    "df_final_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
