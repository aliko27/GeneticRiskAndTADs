{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "from natsort import natsorted, index_natsorted, order_by_index\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dna_features_viewer import GraphicFeature, GraphicRecord\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from bioinf_common.plotting import get_distinct_colors, create_custom_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'MY_RUN/agg_both/pipeline_run/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glob(fname_base, fname_suffix='csv', sep=','):\n",
    "    df_list = []\n",
    "    for fname in tqdm(glob.glob(f'{source_dir}/{fname_base}.do_further_investigations=False,input_files+tad_coordinates=data_newleopoldtads_*.csv.{fname_suffix}')):\n",
    "        # extract meta information\n",
    "        info = dict(e.split('=') for e in '.'.join(fname.split('/')[-1].split('.')[1:-1]).split(','))\n",
    "        _, _, *source, version, k = info['input_files+tad_coordinates'].split('.')[0].split('_')\n",
    "        source = '_'.join(source)\n",
    "\n",
    "        # skip, as we have only hg19 data for GM1278\n",
    "        if source == 'Rao_GM1278_40k':\n",
    "            continue\n",
    "\n",
    "        # read data\n",
    "        tmp = pd.read_csv(fname, sep=sep)\n",
    "        tmp['source'] = source\n",
    "        tmp['version'] = version\n",
    "        tmp['window_size'] = k\n",
    "        df_list.append(tmp)\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease/SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = read_glob('final')\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads = read_glob('tads_hg38', fname_suffix='tsv', sep='\\t')\n",
    "df_tads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precompute coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tad_intervals(df_tads, border_size=20_000):\n",
    "    # prepare\n",
    "    tmp = (df_tads.reset_index()\n",
    "                  .rename(columns={'index': 'tad_idx'}))\n",
    "    \n",
    "    # define TAD sections\n",
    "    df_tad_body = tmp.copy()\n",
    "    df_tad_body['start'] = tmp['tad_start'] + border_size\n",
    "    df_tad_body['stop'] = tmp['tad_stop'] - border_size\n",
    "    \n",
    "    foo = []\n",
    "    for row in tqdm(tmp.itertuples(), total=tmp.shape[0]):\n",
    "        foo.extend([\n",
    "            {\n",
    "                'start': row.tad_start,\n",
    "                'stop': row.tad_start + border_size,\n",
    "                'border_side': 'left',\n",
    "                **row._asdict()\n",
    "            },\n",
    "            {\n",
    "                'start': row.tad_stop - border_size,\n",
    "                'stop': row.tad_stop,\n",
    "                'border_side': 'right',\n",
    "                **row._asdict()\n",
    "            }\n",
    "        ])\n",
    "    df_tad_border = pd.DataFrame(foo)\n",
    "    \n",
    "    return df_tad_body, df_tad_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tad_body, df_tad_border = get_tad_intervals(df_tads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tad_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tad_border.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_snp_features(sub_final):\n",
    "    return [GraphicFeature(start=row.position, end=row.position+1, label=row.snpId, color='black')\n",
    "            for row in sub_final.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tad_features(sub_body, sub_border):\n",
    "    features_tads = collections.defaultdict(list)\n",
    "    \n",
    "    # body\n",
    "    for row in sub_body.itertuples():\n",
    "        features_tads[row.window_size].append(GraphicFeature(\n",
    "            start=row.start, end=row.stop,\n",
    "            color='blue'))  # label=f'{row.tad_idx}', \n",
    "        \n",
    "    # border\n",
    "    for row in sub_border.itertuples():\n",
    "        features_tads[row.window_size].append(GraphicFeature(\n",
    "            start=row.start, end=row.stop,\n",
    "            color='red'))  # label=f'{row.tad_idx}', \n",
    "    \n",
    "    return dict(features_tads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_column(features_snps, features_tads, title, plot_region, ax_list, annotation=None):\n",
    "    ax_list[0].set_title(title)\n",
    "\n",
    "    # annotate\n",
    "    if annotation is not None:\n",
    "        ax_list[0].annotate(\n",
    "            annotation,\n",
    "            xy=(0, 1), xytext=(0, 1),\n",
    "            xycoords='axes fraction',\n",
    "            rotation=90, fontsize=10)\n",
    "    \n",
    "    # plot SNPs\n",
    "    record = GraphicRecord(sequence_length=plot_region[1]+1_000_000, features=features_snps)\n",
    "    record_zoom = record.crop(plot_region)\n",
    "    record_zoom.plot(ax=ax_list[0])\n",
    "\n",
    "    # plot TADs for each window size in own axis\n",
    "    for i, window_size in enumerate(natsorted(features_tads.keys())):\n",
    "        sub_features = features_tads[window_size]\n",
    "\n",
    "        record = GraphicRecord(sequence_length=plot_region[1]+1_000_000, features=sub_features)\n",
    "        record_zoom = record.crop(plot_region)\n",
    "        record_zoom.plot(ax=ax_list[i+1], with_ruler=False)\n",
    "\n",
    "        ax_list[i+1].axis('on')\n",
    "        ax_list[i+1].tick_params(\n",
    "            axis='y', which='both',\n",
    "            left=False, labelleft=False)\n",
    "        ax_list[i+1].axes.get_xaxis().set_visible(False)\n",
    "        [s.set_visible(False) for s in ax_list[i+1].spines.values()]\n",
    "        ax_list[i+1].set_ylabel(window_size, rotation=0, size='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ws(\n",
    "    case_idx, snp_list, df_final, df_body, df_border, \n",
    "    out_dir='images', plot_window=30_000, figsize=(20, 30)\n",
    "):\n",
    "    # check that sources match\n",
    "    base_source = df_final.iloc[0]['source']\n",
    "    print(f'Using source \"{base_source}\"')\n",
    "    \n",
    "    assert [base_source] == \\\n",
    "        df_final['source'].unique().tolist() == \\\n",
    "        df_body['source'].unique().tolist() == \\\n",
    "        df_border['source'].unique().tolist(), \\\n",
    "    'All data must be from same source'\n",
    "    \n",
    "    # check that all SNPs are known\n",
    "    assert df_final.loc[df_final['snpId'].isin(snp_list), 'snpId'].unique().size == len(set(snp_list)), 'Unknown SNPs'\n",
    "    \n",
    "    # check that SNPs all lie on same chromosome\n",
    "    chrom_sub = df_final.loc[df_final['snpId'].isin(snp_list), 'chromosome']\n",
    "    assert chrom_sub.unique().size == 1, 'All SNPs must lie on same chromosome'\n",
    "\n",
    "    cur_chrom = 'chr' + chrom_sub.iloc[0]\n",
    "    print(f'All SNPs are on chromesome \"{cur_chrom}\"')\n",
    "    \n",
    "    # generate SNP features\n",
    "    features_snps_hg19 = generate_snp_features(\n",
    "        df_final[(df_final['version'] == 'hg19') & (df_final['snpId'].isin(snp_list))].drop_duplicates(subset='snpId')\n",
    "    )\n",
    "    features_snps_hg38 = generate_snp_features(\n",
    "        df_final[(df_final['version'] == 'hg38') & (df_final['snpId'].isin(snp_list))].drop_duplicates(subset='snpId')\n",
    "    )\n",
    "    \n",
    "    print(f'SNPs (hg19): {len(features_snps_hg19)}')\n",
    "    print(f'SNPs (hg38): {len(features_snps_hg38)}')\n",
    "    \n",
    "    # generate TAD features\n",
    "    features_tads_hg19 = generate_tad_features(\n",
    "        df_body[(df_body['version'] == 'hg19') & (df_body['chrname'] == cur_chrom)],\n",
    "        df_border[(df_border['version'] == 'hg19') & (df_border['chrname'] == cur_chrom)])\n",
    "    features_tads_hg38 = generate_tad_features(\n",
    "        df_body[(df_body['version'] == 'hg38') & (df_body['chrname'] == cur_chrom)],\n",
    "        df_border[(df_border['version'] == 'hg38') & (df_border['chrname'] == cur_chrom)])\n",
    "\n",
    "    print(f'TADs (hg19): {len(features_tads_hg19)}')\n",
    "    print(f'TADs (hg38): {len(features_tads_hg38)}')\n",
    "    \n",
    "    # determine plot region\n",
    "    all_snp_positions = [gf.start for gf in (features_snps_hg19+features_snps_hg38) if gf.label is not None and gf.label.startswith('rs')]\n",
    "    \n",
    "    region_start = min(all_snp_positions) - plot_window\n",
    "    region_end = max(all_snp_positions) + plot_window\n",
    "    \n",
    "    print(f'Plot region: {region_start}-{region_end}')\n",
    "    \n",
    "    # do actual plot\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=1 + len(features_tads_hg38), ncols=2,\n",
    "        gridspec_kw={'height_ratios': [5] + [1] * len(features_tads_hg38)},\n",
    "        figsize=figsize)\n",
    "    \n",
    "    plot_column(features_snps_hg19, features_tads_hg19, 'hg19', (region_start, region_end), ax[:,0])\n",
    "    plot_column(features_snps_hg38, features_tads_hg38, 'hg38', (region_start, region_end), ax[:,1])\n",
    "\n",
    "#         disease_list = [d for gf in features_snps for d in get_associated_diseases(gf.label)]\n",
    "#         disease_counts = collections.Counter(disease_list)\n",
    "#         common_disease, _ = disease_counts.most_common(1)[0]\n",
    "\n",
    "#         for gf in features_snps:\n",
    "#             if common_disease in get_associated_diseases(gf.label):\n",
    "#                 gf.label = f'|{gf.label}|'\n",
    "#                 gf.color = 'green'\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{out_dir}/coordinate_comparison_{case_idx}.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_final = pd.DataFrame({\n",
    "    'snpId': ['rs1', 'rs1'],\n",
    "    'chromosome': ['1', '1'],\n",
    "    'position': [113, 150],\n",
    "    'source': ['artificial', 'artificial'],\n",
    "    'version': ['hg19', 'hg38'],\n",
    "    'window_size': [1, 1]\n",
    "})\n",
    "\n",
    "tmp_body, tmp_border = get_tad_intervals(pd.DataFrame({\n",
    "    'chrname': ['chr1', 'chr1'],\n",
    "    'tad_start': [100, 60],\n",
    "    'tad_stop': [200, 120],\n",
    "    'source': ['artificial', 'artificial'],\n",
    "    'version': ['hg19', 'hg38'],\n",
    "    'window_size': [1, 1]\n",
    "}), border_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_list = ['rs1']\n",
    "plot_ws(\n",
    "    'minimal_example', snp_list, tmp_final, tmp_body, tmp_border, \n",
    "    plot_window=10, figsize=(20, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_subset = 'dixon_ES_40k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_final = df_final.query(f'TAD_type == \"20in\" and source == \"{source_subset}\"')\n",
    "sub_tad_body = df_tad_body.query(f'source == \"{source_subset}\"')\n",
    "sub_tad_border = df_tad_border.query(f'source == \"{source_subset}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal (real) example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_list = ['rs3798343']\n",
    "plot_ws('minimal_example', snp_list, sub_final, sub_tad_body, sub_tad_border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find SNPs in most inhabited TAD-border of enriched diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_enr = sub_final[(sub_final['version'] == 'hg38') & (sub_final['pval_boundary'] <= .05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "for disease, group in tqdm(sub_enr.groupby('diseaseId')):\n",
    "    sub_group = group.drop_duplicates(subset='snpId')\n",
    "    \n",
    "    # count border memberships\n",
    "    border_counts = collections.defaultdict(set)\n",
    "    for row in tqdm(sub_group.itertuples(), total=sub_group.shape[0], leave=False):\n",
    "        borders = sub_tad_border[\n",
    "            (sub_tad_border['chrname'].str[3:] == row.chromosome) &\n",
    "            (sub_tad_border['start'] <= row.position) &\n",
    "            (sub_tad_border['stop'] >= row.position)\n",
    "        ]\n",
    "        ser_border_idx = borders['Index'].map(str) + '_' + borders['border_side'] + '__' + borders['version'] + '_' + borders['window_size'].map(str)\n",
    "        \n",
    "        for b in ser_border_idx.tolist():\n",
    "            border_counts[b].add(row.snpId)\n",
    "            \n",
    "    # sanity checks\n",
    "    # TODO\n",
    "            \n",
    "    # find best border\n",
    "    bb_idx = max(border_counts.items(), key=lambda x: len(x[1]))[0]\n",
    "    tmp_list.append({\n",
    "        'diseaseId': disease,\n",
    "        'border_idx': bb_idx,\n",
    "        'snp_list': ';'.join(border_counts[bb_idx])\n",
    "    })\n",
    "\n",
    "df_select = pd.DataFrame(tmp_list)\n",
    "df_select.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_select['snp_list'].apply(lambda x: len(x.split(';'))), kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_select.itertuples():\n",
    "    print(row)\n",
    "    plot_ws(\n",
    "        row.diseaseId, row.snp_list.split(';'),\n",
    "        sub_final, sub_tad_body, sub_tad_border)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
